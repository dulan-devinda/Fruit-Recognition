# -*- coding: utf-8 -*-
"""FruitRecognition2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rWczJsGiVa91zFPIAWrZM9_IZMInRF3M
"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
drive.mount('/content/drive')

!rm -rf /root/.config/drive

from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

# Path to your dataset in Google Drive
zip_path = '/content/drive/MyDrive/Fruit Recognition Dataset/archive (1).zip'
extract_path = '/content/dataset/'

# Unzip the dataset
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Verify the files
print("Extracted files:", os.listdir(extract_path))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Directory paths after extraction
train_dir = '/content/extracted_files/fruits-360_dataset_100x100/fruits-360/Training'
validation_dir = '/content/extracted_files/fruits-360_dataset_100x100/fruits-360/Test'

# Create ImageDataGenerator objects for data augmentation
train_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)

# Create generators for loading images from directories
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='categorical'
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Directory paths after extraction
train_dir = '/content/dataset/fruits-360_dataset_100x100/fruits-360/Training'
validation_dir = '/content/dataset/fruits-360_dataset_100x100/fruits-360/Test'

# Create ImageDataGenerator objects for data augmentation
train_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)

# Create generators for loading images from directories
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='categorical'
)

import tensorflow as tf

# Build a CNN model
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(len(os.listdir(train_dir)), activation='softmax')  # Output layer with number of classes
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(
    train_generator,
    epochs=6,  # Adjust based on your needs
    validation_data=validation_generator
)

import zipfile
import os

# Path to your dataset in Google Drive
zip_path = '/content/drive/MyDrive/Fruit Recognition Dataset/archive (1).zip'
extract_path = '/content/dataset/'

# Unzip the dataset
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Verify the files
print("Extracted files:", os.listdir(extract_path))

from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

# Path to your dataset in Google Drive
zip_path = '/content/drive/MyDrive/Fruit Recognition Dataset/archive (1).zip'
extract_path = '/content/dataset/'

# Unzip the dataset
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Verify the files
print("Extracted files:", os.listdir(extract_path))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Directory paths after extraction
train_dir = '/content/extracted_files/fruits-360_dataset_100x100/fruits-360/Training'
validation_dir = '/content/extracted_files/fruits-360_dataset_100x100/fruits-360/Test'

# Create ImageDataGenerator objects for data augmentation
train_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)

# Create generators for loading images from directories
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='categorical'
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Directory paths after extraction
train_dir = '/content/dataset/fruits-360_dataset_100x100/fruits-360/Training'
validation_dir = '/content/dataset/fruits-360_dataset_100x100/fruits-360/Test'

# Create ImageDataGenerator objects for data augmentation
train_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)

# Create generators for loading images from directories
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='categorical'
)

import tensorflow as tf

# Build a CNN model
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(len(os.listdir(train_dir)), activation='softmax')  # Output layer with number of classes
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(
    train_generator,
    epochs=6,  # Adjust based on your needs
    validation_data=validation_generator
)

model.save('/content/drive/MyDrive/my_model.h5')

# Save the model in the native Keras format
model.save('/content/drive/MyDrive/your_model.keras')

import os

# Check if the model file exists
model_path = '/content/drive/MyDrive/your_model.keras'
print("Model saved:", os.path.exists(model_path))

# Load the test data using ImageDataGenerator (similar to training)
test_datagen = ImageDataGenerator(rescale=1./255)

test_dir = '/content/dataset/fruits-360_dataset_100x100/fruits-360/Test'
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(100, 100),
    batch_size=32,
    class_mode='categorical'
)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(test_generator)
print(f'Test Accuracy: {test_accuracy:.2f}')

import numpy as np
from tensorflow.keras.preprocessing import image

# Load and preprocess a new image
img_path = '/content/drive/MyDrive/Fruit Recognition Dataset/bunch-bananas-isolated-on-white-260nw-1722111529.webp'
img = image.load_img(img_path, target_size=(100, 100))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
img_array /= 255.0  # Rescale

# Make a prediction
predictions = model.predict(img_array)
predicted_class = np.argmax(predictions, axis=1)
print(f'Predicted Class: {predicted_class}')

import numpy as np
from tensorflow.keras.preprocessing import image

# Load and preprocess a new image
img_path = '/content/drive/MyDrive/Fruit Recognition Dataset/bunch-bananas-isolated-on-white-260nw-1722111529.webp'
img = image.load_img(img_path, target_size=(100, 100))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
img_array /= 255.0  # Rescale

# Make a prediction
predictions = model.predict(img_array)
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the class index

# Get class names from the training generator
class_names = list(train_generator.class_indices.keys())  # This gives you the fruit names
predicted_class_name = class_names[predicted_class_index]

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

import numpy as np
from tensorflow.keras.preprocessing import image

# Load and preprocess a new image
img_path = '/content/drive/MyDrive/Fruit Recognition Dataset/download (1).jfif'
img = image.load_img(img_path, target_size=(100, 100))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
img_array /= 255.0  # Rescale

# Make a prediction
predictions = model.predict(img_array)
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the class index

# Get class names from the training generator
class_names = list(train_generator.class_indices.keys())  # This gives you the fruit names
predicted_class_name = class_names[predicted_class_index]

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

import matplotlib.pyplot as plt

# Assuming you saved the history during training
history = model.fit(...)

# Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

import matplotlib.pyplot as plt

# Assuming you have a history object from previous training
# history = model.fit(...)

# Plot training & validation accuracy values
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.tight_layout()
plt.show()

import numpy as np
from tensorflow.keras.preprocessing import image

# Load and preprocess a new image
img_path = '/content/dataset/fruits-360_dataset_100x100/fruits-360/Test/Apple Red 1/321_100.jpg'
img = image.load_img(img_path, target_size=(100, 100))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
img_array /= 255.0  # Rescale

# Make a prediction
predictions = model.predict(img_array)
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the class index

# Get class names from the training generator
class_names = list(train_generator.class_indices.keys())  # This gives you the fruit names
predicted_class_name = class_names[predicted_class_index]

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

import numpy as np
from tensorflow.keras.preprocessing import image

# Load and preprocess a new image
img_path = '/content/dataset/fruits-360_dataset_original-size/fruits-360-original-size/Test/cucumber_3/r0_11.jpg'
img = image.load_img(img_path, target_size=(100, 100))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
img_array /= 255.0  # Rescale

# Make a prediction
predictions = model.predict(img_array)
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the class index

# Get class names from the training generator
class_names = list(train_generator.class_indices.keys())  # This gives you the fruit names
predicted_class_name = class_names[predicted_class_index]

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

from tensorflow.keras.preprocessing import image
import numpy as np

def preprocess_image(img_path):
    # Load the image with the same target size as used during training
    img = image.load_img(img_path, target_size=(100, 100))
    img_array = image.img_to_array(img)  # Convert the image to an array
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array /= 255.0  # Normalize the image to [0, 1]
    return img_array

# Specify the path to your test image
img_path = '/content/drive/MyDrive/Fruit Recognition Dataset/download (1).jfif'  # Update this path

# Preprocess the image
preprocessed_image = preprocess_image(img_path)

# Make a prediction
predictions = model.predict(preprocessed_image)
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the class index

# Get class names (assuming you have the class names stored)
class_names = list(train_generator.class_indices.keys())  # Retrieve class names from the training generator
predicted_class_name = class_names[predicted_class_index]  # Get the class name

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')



"""First I tried with 6 epochs. Now Im trying to do it with higher epochs because model not giving the prediction correctly."""

history = model.fit(
    train_generator,
    epochs=6,  # Adjust based on your needs
    validation_data=validation_generator
)

history = model.fit(
    train_generator,
    epochs=20,  # Adjust based on your needs
    validation_data=validation_generator
)

# Save in the Keras native format to Google Drive
model.save('/content/drive/My Drive/ML_Models/my_fruit_model.keras')

!ls '/content/drive/My Drive/ML_Models'

from tensorflow.keras.models import load_model

# Load the saved model
model = load_model('my_fruit_model.keras')  # or 'my_fruit_model.keras' if using the Keras format

from tensorflow.keras.models import load_model

# Set the correct path to the model in Google Drive
model_path = '/content/drive/My Drive/ML_Models/my_fruit_model.keras'  # Or .keras if you used that format

# Load the model
model = load_model(model_path)

from tensorflow.keras.preprocessing import image
import numpy as np

# Load and preprocess a test image
img_path = '/content/drive/MyDrive/Fruit Recognition Dataset/download (1).jfif'  # Replace with the path to your image
img = image.load_img(img_path, target_size=(100, 100))  # Resize image to the size your model expects
img_array = image.img_to_array(img)  # Convert image to array
img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch (1, 100, 100, 3)

# Normalize the image (optional depending on how your training data was preprocessed)
img_array = img_array / 255.0

# Make a prediction
predictions = model.predict(img_array)

# Get the predicted class index and name
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Index of the predicted class
predicted_class_name = class_names[predicted_class_index]  # Get the class name

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

import os

# Assuming your training directory is structured like this:
# /path/to/train/class_name/*.jpg
train_dir = '/content/dataset/fruits-360_dataset_100x100/fruits-360/Training'  # Update with your actual path

# Create a list of class names from the directory names
class_names = os.listdir(train_dir)
class_names.sort()  # Sort to ensure consistent order of class names

from tensorflow.keras.preprocessing import image
import numpy as np

# Load and preprocess a test image
img_path = '/content/drive/MyDrive/Fruit Recognition Dataset/download (1).jfif'  # Replace with the path to your image
img = image.load_img(img_path, target_size=(100, 100))  # Resize image to the size your model expects
img_array = image.img_to_array(img)  # Convert image to array
img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch (1, 100, 100, 3)

# Normalize the image (optional depending on how your training data was preprocessed)
img_array = img_array / 255.0

# Make a prediction
predictions = model.predict(img_array)

# Get the predicted class index and name
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Index of the predicted class
predicted_class_name = class_names[predicted_class_index]  # Get the class name

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

import matplotlib.pyplot as plt

# Assuming you have a history object from previous training
# history = model.fit(...)

# Plot training & validation accuracy values
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.tight_layout()
plt.show()

from tensorflow.keras.models import load_model

# Set the correct path to the model in Google Drive
model_path = '/content/drive/My Drive/ML_Models/my_fruit_model.keras'  # Or .keras if you used that format

# Load the model
model = load_model(model_path)

import os

# Assuming your training directory is structured like this:
# /path/to/train/class_name/*.jpg
train_dir = '/content/dataset/fruits-360_dataset_100x100/fruits-360/Training'  # Update with your actual path

# Create a list of class names from the directory names
class_names = os.listdir(train_dir)
class_names.sort()  # Sort to ensure consistent order of class names

from tensorflow.keras.preprocessing import image
import numpy as np

# Load and preprocess a test image
img_path = '/content/drive/MyDrive/Fruit Recognition Dataset/banana.jfif'  # Replace with the path to your image
img = image.load_img(img_path, target_size=(100, 100))  # Resize image to the size your model expects
img_array = image.img_to_array(img)  # Convert image to array
img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch (1, 100, 100, 3)

# Normalize the image (optional depending on how your training data was preprocessed)
img_array = img_array / 255.0

# Make a prediction
predictions = model.predict(img_array)

# Get the predicted class index and name
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Index of the predicted class
predicted_class_name = class_names[predicted_class_index]  # Get the class name

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

from tensorflow.keras.preprocessing import image
import numpy as np

# Load and preprocess a test image
img_path = '/content/dataset/fruits-360_dataset_100x100/fruits-360/Test/Strawberry 1/325_100.jpg'  # Replace with the path to your image
img = image.load_img(img_path, target_size=(100, 100))  # Resize image to the size your model expects
img_array = image.img_to_array(img)  # Convert image to array
img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch (1, 100, 100, 3)

# Normalize the image (optional depending on how your training data was preprocessed)
img_array = img_array / 255.0

# Make a prediction
predictions = model.predict(img_array)

# Get the predicted class index and name
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Index of the predicted class
predicted_class_name = class_names[predicted_class_index]  # Get the class name

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

from tensorflow.keras.preprocessing import image
import numpy as np

# Load and preprocess a test image
img_path = '/content/dataset/fruits-360_dataset_100x100/fruits-360/Test/Lemon Meyer 1/150_100.jpg'  # Replace with the path to your image
img = image.load_img(img_path, target_size=(100, 100))  # Resize image to the size your model expects
img_array = image.img_to_array(img)  # Convert image to array
img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch (1, 100, 100, 3)

# Normalize the image (optional depending on how your training data was preprocessed)
img_array = img_array / 255.0

# Make a prediction
predictions = model.predict(img_array)

# Get the predicted class index and name
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Index of the predicted class
predicted_class_name = class_names[predicted_class_index]  # Get the class name

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')



from tensorflow.keras.preprocessing import image
import numpy as np

# Load and preprocess a test image
img_path = '/content/drive/MyDrive/Fruit Recognition Dataset/banana1.jfif'  # Replace with the path to your image
img = image.load_img(img_path, target_size=(100, 100))  # Resize image to the size your model expects
img_array = image.img_to_array(img)  # Convert image to array
img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch (1, 100, 100, 3)

# Normalize the image (optional depending on how your training data was preprocessed)
img_array = img_array / 255.0

# Make a prediction
predictions = model.predict(img_array)

# Get the predicted class index and name
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Index of the predicted class
predicted_class_name = class_names[predicted_class_index]  # Get the class name

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

"""It seems like model is working to the images in the test folder. But for the images downloaded from the internet it wont work."""

import tensorflow as tf

# Build a modified CNN model
model = tf.keras.models.Sequential([
    # First convolutional layer
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),

    # Second convolutional layer
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    # Third convolutional layer (new)
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    # Flatten layer to convert 2D output to 1D
    tf.keras.layers.Flatten(),

    # Fully connected layer with 256 units (new, larger than before)
    tf.keras.layers.Dense(256, activation='relu'),

    # Dropout layer to prevent overfitting (optional)
    tf.keras.layers.Dropout(0.5),

    # Output layer for classification
    tf.keras.layers.Dense(len(class_names), activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Print a summary of the model architecture
model.summary()

import os

# Assuming your training directory is structured like this:
# /path/to/train/class_name/*.jpg
train_dir = '/content/dataset/fruits-360_dataset_100x100/fruits-360/Training'  # Update with your actual path

# Create a list of class names from the directory names
class_names = os.listdir(train_dir)
class_names.sort()  # Sort to ensure consistent order of class names

import tensorflow as tf

# Build a modified CNN model
model = tf.keras.models.Sequential([
    # First convolutional layer
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),

    # Second convolutional layer
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    # Third convolutional layer (new)
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    # Flatten layer to convert 2D output to 1D
    tf.keras.layers.Flatten(),

    # Fully connected layer with 256 units (new, larger than before)
    tf.keras.layers.Dense(256, activation='relu'),

    # Dropout layer to prevent overfitting (optional)
    tf.keras.layers.Dropout(0.5),

    # Output layer for classification
    tf.keras.layers.Dense(len(class_names), activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Print a summary of the model architecture
model.summary()

history = model.fit(
    train_generator,
    epochs=20,  # Adjust as needed
    validation_data=validation_generator
)

# Save the model again if necessary
model.save('/content/drive/MyDrive/model_fruit_classifier.h5')

# Save in the Keras native format to Google Drive
model.save('/content/drive/My Drive/ML_Models/my_fruit_modelNew.keras')

from tensorflow.keras.models import load_model

# Set the correct path to the model in Google Drive
model_path = '/content/drive/My Drive/ML_Models/my_fruit_modelNew.keras'  # Or .keras if you used that format

# Load the model
model = load_model(model_path)

import matplotlib.pyplot as plt

# Assuming you have a history object from previous training
# history = model.fit(...)

# Plot training & validation accuracy values
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.tight_layout()
plt.show()

from tensorflow.keras.preprocessing import image
import numpy as np

# Load and preprocess a test image
img_path = '/content/drive/MyDrive/Fruit Recognition Dataset/banana.jfif'  # Replace with the path to your image
img = image.load_img(img_path, target_size=(100, 100))  # Resize image to the size your model expects
img_array = image.img_to_array(img)  # Convert image to array
img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch (1, 100, 100, 3)

# Normalize the image (optional depending on how your training data was preprocessed)
img_array = img_array / 255.0

# Make a prediction
predictions = model.predict(img_array)

# Get the predicted class index and name
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Index of the predicted class
predicted_class_name = class_names[predicted_class_index]  # Get the class name

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

from tensorflow.keras.preprocessing import image
import numpy as np

# Load and preprocess a test image
img_path = '/content/drive/MyDrive/Fruit Recognition Dataset/download (1).jfif'  # Replace with the path to your image
img = image.load_img(img_path, target_size=(100, 100))  # Resize image to the size your model expects
img_array = image.img_to_array(img)  # Convert image to array
img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch (1, 100, 100, 3)

# Normalize the image (optional depending on how your training data was preprocessed)
img_array = img_array / 255.0

# Make a prediction
predictions = model.predict(img_array)

# Get the predicted class index and name
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Index of the predicted class
predicted_class_name = class_names[predicted_class_index]  # Get the class name

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

from tensorflow.keras.preprocessing import image
import numpy as np

# Load and preprocess a test image
img_path = '/content/drive/MyDrive/Fruit Recognition Dataset/onion.jfif'  # Replace with the path to your image
img = image.load_img(img_path, target_size=(100, 100))  # Resize image to the size your model expects
img_array = image.img_to_array(img)  # Convert image to array
img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch (1, 100, 100, 3)

# Normalize the image (optional depending on how your training data was preprocessed)
img_array = img_array / 255.0

# Make a prediction
predictions = model.predict(img_array)

# Get the predicted class index and name
predicted_class_index = np.argmax(predictions, axis=1)[0]  # Index of the predicted class
predicted_class_name = class_names[predicted_class_index]  # Get the class name

print(f'Predicted Class Index: {predicted_class_index}')
print(f'Predicted Class Name: {predicted_class_name}')

# Evaluate the model on the training data
train_loss, train_accuracy = model.evaluate(train_generator)
print(f'Training Loss: {train_loss}')
print(f'Training Accuracy: {train_accuracy * 100:.2f}%')

# Evaluate the model on the validation data
val_loss, val_accuracy = model.evaluate(validation_generator)
print(f'Validation Loss: {val_loss}')
print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')

from sklearn.metrics import confusion_matrix, classification_report
import numpy as np

# Get true labels and predictions
true_labels = validation_generator.classes
predictions = model.predict(validation_generator)
predicted_labels = np.argmax(predictions, axis=1)

# Confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)
print('Confusion Matrix:')
print(cm)

# Classification report
print('Classification Report:')
print(classification_report(true_labels, predicted_labels, target_names=class_names))